Dataset: LON_course_comb_df1, Learning Rate: 0.002

epoch: 0
auc:0.7251727270693706 f1: 0.4792587055402998 recall: 0.3750353381333045 precision: 0.6637038614045826

auc:0.7218767074895103 f1: 0.4800693643408453 recall: 0.37652402001262936 precision: 0.6621676454885211

epoch: 1
auc:0.7302406923149134 f1: 0.4880450687458625 recall: 0.3846924229027194 precision: 0.6673327246641451

auc:0.7262984973449413 f1: 0.4884393063583815 recall: 0.38582600670325934 precision: 0.6654100695317081

epoch: 2
auc:0.7327196976272389 f1: 0.4917759931747504 recall: 0.3883224762557819 precision: 0.6703702357650553

auc:0.7286004070910108 f1: 0.4919190213804429 recall: 0.3892019235439841 precision: 0.6682930897868968

epoch: 3
auc:0.7347202753014384 f1: 0.49352894694250593 recall: 0.38976306909432124 precision: 0.6725917699018595

auc:0.7302382880563834 f1: 0.49304568878785315 recall: 0.3897969592461262 precision: 0.6706993459955285

epoch: 4
auc:0.7362571814546104 f1: 0.4989415016487603 recall: 0.396584080697259 precision: 0.6725164093697884

auc:0.731217147995435 f1: 0.4980483639801177 recall: 0.3966702287851557 precision: 0.6690357201376372

epoch: 5
auc:0.7375207307845834 f1: 0.501056347343636 recall: 0.39871940619906043 precision: 0.6740644702054098

auc:0.732046578702867 f1: 0.4998058163708223 recall: 0.3985160538203721 precision: 0.6701313021992608

epoch: 6
auc:0.738505370216732 f1: 0.5021858646161985 recall: 0.3997148889329989 precision: 0.6753079143124263

auc:0.7327250498132741 f1: 0.5009017235475401 recall: 0.39968183805314034 precision: 0.6707766930931176

epoch: 7
auc:0.7394175460751826 f1: 0.5042070026237221 recall: 0.4022592345309201 precision: 0.6753718908110401

auc:0.7331782497866701 f1: 0.5018536526072688 recall: 0.4011026375868266 precision: 0.6701972242512783

epoch: 8
auc:0.7402411983694417 f1: 0.5060612507318872 recall: 0.4042080949889023 precision: 0.6765361750537353

auc:0.7336444328762862 f1: 0.5028261018003596 recall: 0.4024141448486909 precision: 0.670009502820518

epoch: 9
auc:0.7410358350969939 f1: 0.5087469082747516 recall: 0.4076637133009726 precision: 0.6764867346735073

auc:0.7340424641488916 f1: 0.5050746449261113 recall: 0.4054986156312236 precision: 0.6694735153775212

epoch: 10
auc:0.7416244635989547 f1: 0.5093612014464497 recall: 0.40816897341970876 precision: 0.6772677142956949

auc:0.7343298867726571 f1: 0.5057163596769803 recall: 0.4060936513333657 precision: 0.6701066046809875

epoch: 11
auc:0.7421441806937614 f1: 0.5099555674025795 recall: 0.4085118285002797 precision: 0.6784256923806907

auc:0.734482018489853 f1: 0.505938242280285 recall: 0.4060936513333657 precision: 0.6708863298960799

epoch: 12
auc:0.7425884035616453 f1: 0.5106059725064381 recall: 0.4093599436995868 precision: 0.6783907576218221

auc:0.734674030078952 f1: 0.5063867095974484 recall: 0.40679797930732986 precision: 0.6705432563353216

epoch: 13
auc:0.7429927898973694 f1: 0.5113977946522941 recall: 0.41035542643352524 precision: 0.678454577097111

auc:0.7348488914375846 f1: 0.5069101454528977 recall: 0.407550881624326 precision: 0.6703351575919786

epoch: 14
auc:0.7434508843114735 f1: 0.5123712941801853 recall: 0.41163662173460613 precision: 0.6783836160964318

auc:0.7349343224728762 f1: 0.5080178828567335 recall: 0.4091416913586244 precision: 0.6699143021891715

epoch: 15
auc:0.7438187608989594 f1: 0.5143499021321933 recall: 0.414514799910978 precision: 0.6775322600467003

auc:0.7350329588243188 f1: 0.5092156022288898 recall: 0.4111575265944528 precision: 0.6686943297849228

epoch: 16
auc:0.74412783901546 f1: 0.5148256274892037 recall: 0.41500502252618027 precision: 0.6778736803839598

auc:0.7351303938047405 f1: 0.5095145047347062 recall: 0.4116432700247729 precision: 0.6684413945417258

epoch: 17
auc:0.7444185453001287 f1: 0.5142006396078665 recall: 0.413931344773866 precision: 0.6785767110725449

auc:0.7352317692164184 f1: 0.5087669129930918 recall: 0.4105017729635207 precision: 0.668882820847679

epoch: 18
auc:0.7447498940005431 f1: 0.5153421855990207 recall: 0.415299757595443 precision: 0.6788786958103498

auc:0.7352991767568726 f1: 0.5097213975965188 recall: 0.411801136639627 precision: 0.6687373050148889

epoch: 19
auc:0.7450170006561311 f1: 0.5159543824912887 recall: 0.41615388779616364 precision: 0.6787233103285901

auc:0.7353393132284163 f1: 0.5100883812784873 recall: 0.4124568902705591 precision: 0.6682734874569601

epoch: 20
auc:0.7452542615243853 f1: 0.5158392143913828 recall: 0.41580501771417916 precision: 0.6792538112714391

auc:0.7353629414790425 f1: 0.5096790186519234 recall: 0.411971146840239 precision: 0.6681437715411127

epoch: 21
auc:0.7455616114830881 f1: 0.517837920244817 recall: 0.4188395859273027 precision: 0.6781208458920285

auc:0.7353829801310638 f1: 0.5113521525298119 recall: 0.41476417156457956 precision: 0.6665820956693144

epoch: 22
auc:0.745761579238701 f1: 0.5170233771071994 recall: 0.4173869630859363 precision: 0.6791453794507409

auc:0.7354105053139588 f1: 0.5107193473158514 recall: 0.41353766940302134 precision: 0.6676076770765943

epoch: 23
auc:0.7460261156520869 f1: 0.5179131942700106 recall: 0.4185749258651076 precision: 0.6790745104927519

auc:0.7354679949520622 f1: 0.5106985313391701 recall: 0.41403555641909945 precision: 0.6662432828529555

epoch: 24
auc:0.7462011825790122 f1: 0.5181132798476159 recall: 0.41884259342800945 precision: 0.6790581558070478

auc:0.7355128739673175 f1: 0.5112781954887219 recall: 0.41453344343517756 precision: 0.666927164738981

epoch: 25
auc:0.7464522042578308 f1: 0.5191319564417792 recall: 0.4202320587545338 precision: 0.6789108506792607

auc:0.7354881404873106 f1: 0.5117294379737751 recall: 0.41562636615339776 precision: 0.6656423820451982

epoch: 26
auc:0.7466450833679955 f1: 0.519182802573815 recall: 0.4200546162128348 precision: 0.6795486834166943

auc:0.7354378950729641 f1: 0.5114444984847918 recall: 0.41501918686549766 precision: 0.6662377916837242

epoch: 27
auc:0.7468463151392694 f1: 0.5204136130314809 recall: 0.42200046917011025 precision: 0.6786878585317249

auc:0.7354743550367013 f1: 0.5127006645262451 recall: 0.41692572982950404 precision: 0.6656004032414408

epoch: 28
auc:0.7469763824377001 f1: 0.5195025805816113 recall: 0.420331306277857 precision: 0.6799202160005838

auc:0.7355327125239957 f1: 0.5119093928603489 recall: 0.41549278671005974 precision: 0.6665952306733167

epoch: 29
auc:0.7471975416319186 f1: 0.5207267386333501 recall: 0.4222410692266513 precision: 0.6791306493041614

