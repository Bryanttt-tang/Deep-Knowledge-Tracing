Dataset: LON_course_comb_df1, Learning Rate: 0.002

epoch: 0
auc:0.6685937959017009 f1: 0.3900399938218254 recall: 0.2866036091075271 precision: 0.6102995243604576

auc:0.6670990934895515 f1: 0.3904575985176852 recall: 0.2866804652654287 precision: 0.6119985064099904

epoch: 1
auc:0.6745887043090383 f1: 0.3924810841778779 recall: 0.28784479823432396 precision: 0.6166396805115126

auc:0.6727238295998961 f1: 0.3933891745745639 recall: 0.2884295834183599 precision: 0.6184394207729972

epoch: 2
auc:0.6798768427703233 f1: 0.39517526829308586 recall: 0.28876482363765005 precision: 0.6257744798425922

auc:0.6778262550856996 f1: 0.39590775145842894 recall: 0.2891778172948916 precision: 0.6275092780026991

epoch: 3
auc:0.6849650134274908 f1: 0.4012911263006175 recall: 0.2948065652626419 precision: 0.628196684195902

auc:0.6823682742565825 f1: 0.4025943942552699 recall: 0.29555238123001876 precision: 0.6311999335906695

epoch: 4
auc:0.6881086237124034 f1: 0.4109306053376512 recall: 0.30549914396586486 precision: 0.6274823926197798

auc:0.6852152855287157 f1: 0.41167163554579217 recall: 0.30593048227074404 precision: 0.6291189576963812

epoch: 5
auc:0.6917846731774011 f1: 0.41260827922421095 recall: 0.3063588002482378 precision: 0.6316856036088069

auc:0.6887138844382454 f1: 0.4138508431118611 recall: 0.3074172327007356 precision: 0.6330111851451667

epoch: 6
auc:0.6945993595668046 f1: 0.41775497487274516 recall: 0.3116398909492199 precision: 0.6334472061884007

auc:0.6913584886647284 f1: 0.41807298756619093 recall: 0.3118677666676384 precision: 0.6339680783817951

epoch: 7
auc:0.6964538994410204 f1: 0.4212880576431794 recall: 0.314989169779701 precision: 0.6358761620169738

auc:0.6928708017570656 f1: 0.42183564844865634 recall: 0.31575469589637445 precision: 0.6352563977243847

epoch: 8
auc:0.6983850529195201 f1: 0.42695646882876076 recall: 0.32193886298382834 precision: 0.6336579546480734

auc:0.6945626329973243 f1: 0.42776198487749223 recall: 0.32242077952365683 precision: 0.6353400735294118

epoch: 9
auc:0.7007867793305023 f1: 0.43420724134586175 recall: 0.32968301381969917 precision: 0.6357768857512737

auc:0.696858300571011 f1: 0.43515072452646786 recall: 0.3306222001962899 precision: 0.6363313321737829

epoch: 10
auc:0.7025840063226927 f1: 0.43374630516360857 recall: 0.3286543239986574 precision: 0.6376413706511249

auc:0.6983300786417934 f1: 0.43505669805881214 recall: 0.3299419875812611 precision: 0.6384611045298133

epoch: 11
auc:0.703126945815922 f1: 0.4374378075895769 recall: 0.33279081616636763 precision: 0.6380855812058412

auc:0.6987722310668923 f1: 0.4383582613132634 recall: 0.3339260900407156 precision: 0.6378350285841562

epoch: 12
