
Dataset: LON_sem1, Learning Rate: 0.005





loading train data:    : 3861it [00:26, 105.74it/s]
loading train data:    : 4000it [00:29, 134.73it/s]
loading test data:    : 1045it [00:01, 647.61it/s]










































































































Training:    : 100%|██████████| 109/109 [20:11<00:00, 11.11s/it]






































Testing:    :  35%|███▍      | 38/109 [05:25<10:07,  8.56s/it]
Traceback (most recent call last):
  File "/cluster/home/yutang/Deep-Knowledge-Tracing/DKT/KnowledgeTracing/evaluation/./run.py", line 53, in <module>
    train_auc, train_f1, train_recall, train_precision,val_loss=eval.test(trainLoaders, model,loss_func, device)
  File "/cluster/home/yutang/Deep-Knowledge-Tracing/DKT/KnowledgeTracing/evaluation/eval.py", line 100, in test
    pred_epoch, gold_epoch, val_loss = test_epoch(model, testLoaders[i],loss_func,device)
  File "/cluster/home/yutang/Deep-Knowledge-Tracing/DKT/KnowledgeTracing/evaluation/eval.py", line 62, in test_epoch
    batch = batch.to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 202.00 MiB (GPU 0; 23.69 GiB total capacity; 20.90 GiB already allocated; 176.06 MiB free; 22.21 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF