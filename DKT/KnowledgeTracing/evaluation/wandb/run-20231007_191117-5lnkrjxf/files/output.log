
Dataset: assist2009, Learning Rate: 0.002

loading train data:    : 3361it [00:07, 478.74it/s]
loading test data:    : 856it [00:00, 1885.32it/s]
epoch: 0
Training:    :   0%|          | 0/160 [00:00<?, ?it/s]..\evaluation\eval.py:33: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  a = (((batch[student][:, 0:C.NUM_OF_QUESTIONS] - batch[student][:, C.NUM_OF_QUESTIONS:]).sum(1) + 1)//2)[1:]
Training:    :   0%|          | 0/160 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "D:\ETHz\Internship\adaptive-e-learning-for-educational-recommendation-system\DeepKnowledgeTracing-DKT-Pytorch\DKT\KnowledgeTracing\evaluation\run.py", line 41, in <module>
    model, optimizer, train_loss = eval.train(trainLoaders, model, optimizer_adgd, loss_func,device)
  File "..\evaluation\eval.py", line 90, in train
    model, optimizer, loss = train_epoch(model, trainLoaders[i], optimizer, lossFunc,device)
  File "..\evaluation\eval.py", line 47, in train_epoch
    loss = loss_func(pred, batch)
  File "C:\Users\tyu06\anaconda3\lib\site-packages\torch\nn\modules\module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "..\evaluation\eval.py", line 36, in forward
    loss = loss - (a[i]*torch.log(p[i]) + (1-a[i])*torch.log(1-p[i]))
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!