
Dataset: LON_sem1, Learning Rate: 0.002






loading train data:    : 4000it [00:33, 119.00it/s]
loading test data:    : 1042it [00:01, 583.78it/s]
Training:    :   0%|          | 0/775 [00:00<?, ?it/s]




















































































































































































































































































































































































































































































































































































































Training:    : 100%|██████████| 775/775 [26:14<00:00,  2.03s/it]


































































































































































































































































Testing:    :  67%|██████▋   | 518/775 [14:20<07:06,  1.66s/it]
Traceback (most recent call last):
  File "/cluster/home/yutang/Deep-Knowledge-Tracing/DKT/KnowledgeTracing/evaluation/./run.py", line 48, in <module>
    train_auc, train_f1, train_recall, train_precision,val_loss=eval.test(trainLoaders, model,loss_func, device)
  File "/cluster/home/yutang/Deep-Knowledge-Tracing/DKT/KnowledgeTracing/evaluation/eval.py", line 101, in test
    pred_epoch, gold_epoch, val_loss = test_epoch(model, testLoaders[i],loss_func,device)
  File "/cluster/home/yutang/Deep-Knowledge-Tracing/DKT/KnowledgeTracing/evaluation/eval.py", line 64, in test_epoch
    pred = model(batch)# output: torch.size([batch_size, sequence_length, n_questions])
  File "/cluster/home/yutang/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/cluster/home/yutang/Deep-Knowledge-Tracing/DKT/KnowledgeTracing/model/RNNModel.py", line 24, in forward
    out,hn = self.rnn(x, h0)
  File "/cluster/home/yutang/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/cluster/home/yutang/miniconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py", line 509, in forward
    result = _VF.rnn_tanh(input, hx, self._flat_weights, self.bias, self.num_layers,
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 60.00 MiB (GPU 0; 31.74 GiB total capacity; 29.66 GiB already allocated; 15.12 MiB free; 30.59 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF