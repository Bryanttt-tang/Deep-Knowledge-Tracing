
Dataset: LON_course_comb_df1, Learning Rate: 0.002
loading train data:    : 1666it [00:04, 365.00it/s]
loading test data:    : 412it [00:00, 936.37it/s]
Training:    :   0%|          | 0/365 [00:00<?, ?it/s]




























































































































































































Training:    : 100%|██████████| 365/365 [11:19<00:00,  1.86s/it]























































































































































































Testing:    : 100%|██████████| 365/365 [09:17<00:00,  1.53s/it]
auc:0.7054320959237107 f1: 0.45035439919178033 recall: 0.3440054963929921 precision: 0.6518834016079009












































Testing:    : 100%|██████████| 89/89 [02:22<00:00,  1.61s/it]
auc:0.7028156655570816 f1: 0.4505962631585762 recall: 0.344977992783219 precision: 0.6494233568469376
epoch: 1



































































































































































































Training:    : 100%|██████████| 365/365 [11:39<00:00,  1.92s/it]






















































































































































































Testing:    : 100%|██████████| 365/365 [09:33<00:00,  1.57s/it]
auc:0.7071113337688727 f1: 0.454315615524125 recall: 0.3494380919664327 precision: 0.6491446387791103













































Testing:    : 100%|██████████| 89/89 [02:01<00:00,  1.37s/it]
auc:0.7042709871135915 f1: 0.4545419444515947 recall: 0.3501030968714065 precision: 0.6477806309611152
epoch: 2
































































































































































































Training:    : 100%|██████████| 365/365 [11:30<00:00,  1.89s/it]




















































































































































































Testing:    :  99%|█████████▉| 362/365 [08:54<00:04,  1.48s/it]
Traceback (most recent call last):
  File "/cluster/home/yutang/Deep-Knowledge-Tracing/DKT/KnowledgeTracing/evaluation/./run.py", line 50, in <module>
    train_auc, train_f1, train_recall, train_precision,val_loss=eval.test(trainLoaders, model,loss_func, device)
  File "/cluster/home/yutang/Deep-Knowledge-Tracing/DKT/KnowledgeTracing/evaluation/eval.py", line 109, in test
    pred_epoch, gold_epoch, val_loss = test_epoch(model, testLoaders[i],loss_func,device)
  File "/cluster/home/yutang/Deep-Knowledge-Tracing/DKT/KnowledgeTracing/evaluation/eval.py", line 72, in test_epoch
    pred = model(batch)# output: torch.size([batch_size, sequence_length, n_questions])
  File "/cluster/home/yutang/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/cluster/home/yutang/Deep-Knowledge-Tracing/DKT/KnowledgeTracing/model/RNNModel.py", line 22, in forward
    # out,(hn, cn) = self.rnn(x, (h0, c0))
  File "/cluster/home/yutang/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/cluster/home/yutang/miniconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py", line 812, in forward
    result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 42.00 MiB (GPU 0; 31.74 GiB total capacity; 29.48 GiB already allocated; 27.12 MiB free; 30.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF