
Dataset: assist2009, Learning Rate: 0.002

loading train data:    : 3361it [00:06, 511.15it/s]
loading test data:    : 856it [00:00, 2532.25it/s]
epoch: 0
Training:    :   0%|          | 0/160 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "D:\ETHz\Internship\adaptive-e-learning-for-educational-recommendation-system\DeepKnowledgeTracing-DKT-Pytorch\DKT\KnowledgeTracing\evaluation\run.py", line 41, in <module>
    model, optimizer, train_loss = eval.train(trainLoaders, model, optimizer_adgd, loss_func,device)
  File "..\evaluation\eval.py", line 90, in train
    model, optimizer, loss = train_epoch(model, trainLoaders[i], optimizer, lossFunc,device)
  File "..\evaluation\eval.py", line 47, in train_epoch
    loss = loss_func(pred, batch)
  File "C:\Users\tyu06\anaconda3\lib\site-packages\torch\nn\modules\module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "..\evaluation\eval.py", line 32, in forward
    p = temp.gather(0, index)[0]
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_gather)